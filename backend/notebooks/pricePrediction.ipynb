{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "\n",
      "Training segmented models...\n",
      "\n",
      "Budget Segment Metrics:\n",
      "MAE: ₹122.03\n",
      "RMSE: ₹238.16\n",
      "R² Score: 0.9820\n",
      "\n",
      "Mid Segment Metrics:\n",
      "MAE: ₹472.58\n",
      "RMSE: ₹1,948.61\n",
      "R² Score: 0.8295\n",
      "\n",
      "Premium Segment Metrics:\n",
      "MAE: ₹1,183.88\n",
      "RMSE: ₹2,793.63\n",
      "R² Score: 0.7866\n",
      "\n",
      "Flagship Segment Metrics:\n",
      "MAE: ₹6,371.46\n",
      "RMSE: ₹12,330.18\n",
      "R² Score: 0.8014\n",
      "\n",
      "Saving models and artifacts...\n",
      "\n",
      "Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_and_preprocess_data(filepath):\n",
    "    \"\"\"Load and preprocess the dataset with advanced feature engineering.\"\"\"\n",
    "    data = pd.read_csv(filepath)\n",
    "    \n",
    "    # Define brand tiers\n",
    "    # premium_brands = ['Apple', 'Google', 'OnePlus']\n",
    "    # mid_brands = ['Nothing', 'Samsung']\n",
    "    \n",
    "    # Create brand tiers\n",
    "    data['price_segment'] = data['Price (Rs.)'].apply(\n",
    "        lambda x: 'flagship' if x >= 50000\n",
    "        else 'premium' if x >= 30000\n",
    "        else 'mid' if x >= 15000\n",
    "        else 'budget'\n",
    "    )\n",
    "    \n",
    "    # Create RAM tiers\n",
    "    data['ram_tier'] = data['RAM (GB)'].apply(\n",
    "        lambda x: 'high' if x >= 12\n",
    "        else 'mid' if x >= 6\n",
    "        else 'basic'\n",
    "    )\n",
    "    \n",
    "    # Create ROM tiers\n",
    "    data['rom_tier'] = data['ROM (GB)'].apply(\n",
    "        lambda x: 'high' if x >= 256\n",
    "        else 'mid' if x >= 128\n",
    "        else 'basic'\n",
    "    )\n",
    "    \n",
    "    # Create interaction features\n",
    "    data['storage_per_ram'] = data['ROM (GB)'] / data['RAM (GB)']\n",
    "    data['camera_total'] = data['Front Camera (MP)'] + data['Back Camera (MP)']\n",
    "    data['price_per_ram'] = data['Price (Rs.)'] / data['RAM (GB)']\n",
    "    data['price_per_rom'] = data['Price (Rs.)'] / data['ROM (GB)']\n",
    "    data['price_per_front_camera'] = data['Price (Rs.)'] / data['Front Camera (MP)']\n",
    "    data['price_per_back_camera'] = data['Price (Rs.)'] / data['Back Camera (MP)']\n",
    "    \n",
    "    # Log transform the price\n",
    "    data['Log_Price'] = np.log(data['Price (Rs.)'])\n",
    "    \n",
    "    # One-hot encode categorical features\n",
    "    categorical_columns = ['Brand', 'ram_tier', 'rom_tier']\n",
    "    data_encoded = pd.get_dummies(data, columns=categorical_columns)\n",
    "    \n",
    "    return data_encoded\n",
    "\n",
    "def train_segmented_models(X, y, segment_column='price_segment'):\n",
    "    \"\"\"Train separate models for different price segments.\"\"\"\n",
    "    models = {}\n",
    "    scalers = {}\n",
    "    feature_columns = None\n",
    "    \n",
    "    for segment in ['budget', 'mid', 'premium', 'flagship']:\n",
    "        # Filter data for this segment\n",
    "        segment_mask = X[segment_column] == segment\n",
    "        X_segment = X[segment_mask].drop(columns=[segment_column])\n",
    "        y_segment = y[segment_mask]\n",
    "        \n",
    "        # Store feature columns for the API\n",
    "        if feature_columns is None:\n",
    "            feature_columns = X_segment.columns.tolist()\n",
    "        \n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_segment, y_segment, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = RobustScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Train model\n",
    "        \n",
    "        # model = XGBRegressor(\n",
    "        #         n_estimators=300,\n",
    "        #         learning_rate=0.1,\n",
    "        #         max_depth=7,\n",
    "        #         min_child_weight=1,\n",
    "        #         subsample=0.8,\n",
    "        #         colsample_bytree=0.8,\n",
    "        #         random_state=42\n",
    "        #         )\n",
    "        \n",
    "        model = DecisionTreeRegressor()\n",
    "        \n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate segment performance\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        mae = mean_absolute_error(np.exp(y_test), np.exp(y_pred))\n",
    "        rmse = np.sqrt(mean_squared_error(np.exp(y_test), np.exp(y_pred)))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\n{segment.title()} Segment Metrics:\")\n",
    "        print(f\"MAE: ₹{mae:,.2f}\")\n",
    "        print(f\"RMSE: ₹{rmse:,.2f}\")\n",
    "        print(f\"R² Score: {r2:.4f}\")\n",
    "        \n",
    "        models[segment] = model\n",
    "        scalers[segment] = scaler\n",
    "    \n",
    "    return models, scalers, feature_columns\n",
    "\n",
    "def save_models(models, scalers, feature_columns):\n",
    "    \"\"\"Save the trained models, scalers, and feature columns.\"\"\"\n",
    "    with open('../models/segmented_models.pkl', 'wb') as f:\n",
    "        pickle.dump(models, f)\n",
    "    \n",
    "    with open('../models/segmented_scalers.pkl', 'wb') as f:\n",
    "        pickle.dump(scalers, f)\n",
    "        \n",
    "    with open('../models/feature_columns.pkl', 'wb') as f:\n",
    "        pickle.dump(feature_columns, f)\n",
    "\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    data = load_and_preprocess_data('../data/processed/5g_smartphones_dataset.csv')\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = data.drop(['Model', 'Price (Rs.)', 'Log_Price', 'Clock Speed (GHz)'], axis=1)\n",
    "    y = data['Log_Price']\n",
    "    \n",
    "    # Train segmented models\n",
    "    print(\"\\nTraining segmented models...\")\n",
    "    models, scalers, feature_columns = train_segmented_models(X, y)\n",
    "    \n",
    "    # Save models and artifacts\n",
    "    print(\"\\nSaving models and artifacts...\")\n",
    "    save_models(models, scalers, feature_columns)\n",
    "    \n",
    "    print(\"\\nTraining completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
